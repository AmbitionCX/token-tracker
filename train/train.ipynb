{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb1080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.222.117.105 5432 token_tracer zhuyufei\n"
     ]
    }
   ],
   "source": [
    "POSTGRESQL_HOST=os.getenv(\"POSTGRESQL_HOST\")\n",
    "POSTGRESQL_PORT=os.getenv(\"POSTGRESQL_PORT\")\n",
    "POSTGRESQL_DATABASE=os.getenv(\"POSTGRESQL_DATABASE\")\n",
    "POSTGRESQL_USER=os.getenv(\"POSTGRESQL_USER\")\n",
    "POSTGRESQL_PASSWORD=os.getenv(\"POSTGRESQL_PASSWORD\")\n",
    "\n",
    "print(POSTGRESQL_HOST,POSTGRESQL_PORT,POSTGRESQL_DATABASE,POSTGRESQL_USER)\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=POSTGRESQL_HOST,\n",
    "    port=POSTGRESQL_PORT,\n",
    "    dbname=POSTGRESQL_DATABASE,\n",
    "    user=POSTGRESQL_USER,\n",
    "    password=POSTGRESQL_PASSWORD\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c496d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuyufei\\AppData\\Local\\Temp\\ipykernel_22040\\2148033441.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n"
     ]
    }
   ],
   "source": [
    "# 选择一个 token 的表，比如 \"crv_transactions\"\n",
    "df = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM crv_transactions\n",
    "    limit 10\n",
    "    \"\"\",\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[10, 5], edge_index=[2, 0], edge_attr=[0, 1])\n",
      "Node 0 (tx_hash=0xcac4eadcf267993d1bdc5422e963db6fa22410fef666009a015d8661e8b51652): [-1.4439897537231445, 0.5111734867095947, 0.40480664372444153, 1.2119958400726318, -0.6079502105712891]\n",
      "Node 1 (tx_hash=0xdf7632fe3dc93ec212708c5401c82a1ede1a3a84a9ac858f7df2359344f16fd1): [-0.9282791018486023, -0.8774945139884949, -1.0624866485595703, -0.6498267650604248, -0.5187986493110657]\n",
      "Node 2 (tx_hash=0x0ca5f025586b6a824ecffeed8c07f0b901ac7305149c29e9f86d9f5b738e2179): [-0.9282791018486023, -0.13527540862560272, -0.4274420738220215, 0.6909891963005066, -0.6270541548728943]\n",
      "Node 3 (tx_hash=0x04ceb7f71932d6ce45fa8437a5cd2713225f9849d81b7076ff61bb95196054ce): [-0.41256850957870483, -1.021149754524231, -1.0624866485595703, -1.0965148210525513, -0.25134381651878357]\n",
      "Node 4 (tx_hash=0x818df4c2ddc829716dd95b9771604f5eb8f13b94f5f15481abc41b160b488156): [-0.41256850957870483, 0.7625702619552612, 1.3402550220489502, 0.8721851706504822, -0.6334221363067627]\n"
     ]
    }
   ],
   "source": [
    "# ========== 节点映射 ==========\n",
    "# 每一笔交易就是一个节点\n",
    "# 用 transaction_hash 来标识唯一节点\n",
    "tx_to_idx = {tx: i for i, tx in enumerate(df[\"transaction_hash\"].unique())}\n",
    "\n",
    "# ========== 节点特征 ==========\n",
    "# 选取数值型字段作为节点特征\n",
    "node_features = df[[\n",
    "    \"block_number\", \n",
    "    \"transaction_index\", \n",
    "    \"gas_used\", \n",
    "    \"cumulative_gas_used\", \n",
    "    \"gas_price\"\n",
    "]].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "node_features = torch.tensor(\n",
    "    scaler.fit_transform(node_features),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# ========== 边 ==========\n",
    "# 这里暂时没有规则，就先建一个空的 edge_index\n",
    "# 后面你可以根据规则去生成 edge_index\n",
    "edge_index = torch.empty((2, 0), dtype=torch.long)  \n",
    "\n",
    "# ========== 边特征 ==========\n",
    "# 由于还没有边，所以边特征先为空，后面补充transaction之间连边的规则，相关的transaction之间连一条边\n",
    "edge_features = torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "# ========== 构建图数据 ==========\n",
    "data = Data(\n",
    "    x=node_features,        # 节点特征 (N, F)\n",
    "    edge_index=edge_index,  # 边 (2, E)\n",
    "    edge_attr=edge_features # 边特征 (E, F)\n",
    ")\n",
    "\n",
    "print(data)\n",
    "# 打印前5个节点及其特征\n",
    "for i in range(min(5, data.num_nodes)):\n",
    "    tx_hash = df.iloc[i][\"transaction_hash\"]\n",
    "    features = data.x[i].tolist()\n",
    "    print(f\"Node {i} (tx_hash={tx_hash}): {features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "token",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
